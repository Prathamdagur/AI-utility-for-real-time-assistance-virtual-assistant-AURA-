<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>AURA</title>

        
          rel="stylesheet"
          integrity="sha384-EVSTQN3/azprG1Anm30QgpJLIm9aOQYtZTcTww5p3yD65VohhpuuCOmLASjC"
          crossorigin="anonymous">

    <link rel="stylesheet" href="style.css">
    
    <!-- Audio elements for UI sounds -->
    <audio id="activationSound" preload="auto">
        <source src="sounds/activate.mp3" type="audio/mpeg">
    </audio>
    <audio id="deactivationSound" preload="auto">
        <source src="sounds/deactivate.mp3" type="audio/mpeg">
    </audio>
</head>
<body>

    <section id="Oval" class="mb-4">
        <!-- Simplified centered wrapper to keep AURA perfectly centered -->
        <div class="center-wrapper">
            <!-- panel keeps the emblem and controls aligned in a fixed narrow column -->
            <div class="panel" id="panel">
                <button id="compactBtn" class="compact-btn" title="Open compact window">◧</button>
                <div id="AURA">
                    <div class="square">
                        <span class="circle"></span>
                        <span class="circle"></span>
                        <span class="circle"></span>
                        <div class="aura-title">AURA</div>
                    </div>
                </div>

                <!-- Voice input sits inside the panel so it's horizontally aligned under the emblem -->
                <div class="voice-input" style="position:absolute; bottom:16px; left:50%; transform:translateX(-50%);">
                    <button id="micBtn" class="mic-btn" aria-pressed="false" title="Toggle microphone">
                        <svg width="18" height="18" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" aria-hidden="true">
                                <path d="M12 14a3 3 0 0 0 3-3V6a3 3 0 0 0-6 0v5a3 3 0 0 0 3 3z" stroke="currentColor" stroke-width="1.6" stroke-linecap="round" stroke-linejoin="round"/>
                                <path d="M19 11v1a7 7 0 0 1-14 0v-1" stroke="currentColor" stroke-width="1.6" stroke-linecap="round" stroke-linejoin="round"/>
                                <path d="M12 19v4" stroke="currentColor" stroke-width="1.6" stroke-linecap="round" stroke-linejoin="round"/>
                        </svg>
                    </button>
                    <input id="voiceInput" class="voice-input-field" type="text" placeholder="Type or speak a command" aria-label="Command input">
                    <button id="voiceSend" class="voice-send" title="Send command">
                        <svg width="18" height="18" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" aria-hidden="true">
                                <path d="M22 2L11 13" stroke="currentColor" stroke-width="1.6" stroke-linecap="round" stroke-linejoin="round"/>
                                <path d="M22 2L15 22L11 13L2 9L22 2Z" stroke="currentColor" stroke-width="1.6" stroke-linecap="round" stroke-linejoin="round"/>
                        </svg>
                    </button>
                </div>
                <div id="status" style="position:absolute; bottom:86px; left:50%; transform:translateX(-50%); font-size:12px; color:#666;">Status: Idle</div>
            </div>
        </div>
    </section>

    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js"
            integrity="sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXIpuyJoM9yLunsFapJcXn/tWtIaxVXM"
            crossorigin="anonymous"></script>

    <!-- (voice-input inside panel above — duplicate removed) -->
        <script>
            (function(){
                const statusEl = document.getElementById('status');
                const micBtn = document.getElementById('micBtn');
                const input = document.getElementById('voiceInput');
                const send = document.getElementById('voiceSend');
                let recognition = null;
                let listening = false;
                let shouldResumeRecognition = false; // resume after TTS
                let ttsSpeaking = false;
                let _lastSendTs = 0; // debounce last send

                // Determine API base: if the page is NOT served from port 5000,
                // use the explicit Flask server origin so fetch('/api/command')
                // doesn't accidentally post to port 80 and produce a 405.
                const apiBase = (location.port === '5000' || location.origin.includes(':5000'))
                    ? ''
                    : 'http://127.0.0.1:5000';
                if (apiBase) {
                    console.warn('UI loaded from different origin — routing API requests to ' + apiBase);
                    // show a small warning in the status bar so user knows the page
                    // was opened from another origin (e.g. file:// or :80)
                    try { statusEl.textContent = 'Status: Using API at ' + apiBase; statusEl.style.color = 'orange'; } catch(e){}
                }

                function setStatus(msg, isError=false){
                    if(!statusEl) return;
                    statusEl.textContent = 'Status: ' + msg;
                    statusEl.style.color = isError ? 'crimson' : '#2b8a3e';
                }

                // Initialize Web Speech API (SpeechRecognition)
                const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
                if (SpeechRecognition) {
                    recognition = new SpeechRecognition();
                    recognition.lang = 'en-US';
                    recognition.interimResults = false;
                    recognition.maxAlternatives = 1;
                    // Keep recognition continuous where supported so it doesn't stop after a single result
                    try { recognition.continuous = true; } catch (e) { /* ignore if not supported */ }

                    let activated = false;
                    let activationTimer = null;

                    recognition.addEventListener('start', ()=>{ console.log('Recognition started'); setStatus('Listening'); });
                    recognition.addEventListener('error', (e)=>{ console.error('Recognition error', e); setStatus('Recognition error: ' + (e.error || e.message || e), true); });
                    recognition.addEventListener('nomatch', ()=>{ console.log('No match'); setStatus('No speech recognized'); });

                    recognition.addEventListener('result', (e) => {
                        const text = e.results[0][0].transcript.trim();
                        console.log('Recognition result:', text);
                        input.value = text;

                        const lower = text.toLowerCase();
                        if (!activated) {
                            if (/\b(aura)\b/.test(lower) || /^aura\b/.test(lower)) {
                                const greet = 'Yes? How can I help you?';
                                speakText(greet);
                                activated = true;
                                if (activationTimer) clearTimeout(activationTimer);
                                activationTimer = setTimeout(() => { activated = false; }, 8000);
                                return;
                            }
                            if (!listening) return;
                        }

                        if (activated) {
                            activated = false;
                            if (activationTimer) { clearTimeout(activationTimer); activationTimer = null; }
                            sendCommand(text);
                            return;
                        }

                        sendCommand(text);
                    });

                    recognition.addEventListener('end', () => {
                        if (listening) {
                            try{ recognition.start(); } catch(e){ console.warn('Recognition restart failed', e); setStatus('Idle'); }
                        } else {
                            setStatus('Idle');
                        }
                    });
                } else {
                    console.warn('SpeechRecognition API not supported in this browser.');
                    setStatus('SpeechRecognition not supported', true);
                    micBtn.disabled = true;
                    micBtn.title = 'SpeechRecognition not supported';
                }

                // Function to play UI sounds (safe, non-invasive volume boost)
                async function playSound(soundId) {
                    try {
                        const sound = document.getElementById(soundId);
                        if (sound) {
                            // Ensure element is unmuted and at max safe volume
                            try { sound.muted = false; } catch(e){}
                            try { sound.volume = 1.0; } catch(e){}
                            sound.currentTime = 0;  // Reset to start
                            await sound.play();
                        }
                    } catch (e) {
                        console.warn('Sound playback failed:', e);
                    }
                }

                micBtn.addEventListener('click', async function(){
                    if(!recognition && !(window.SpeechRecognition || window.webkitSpeechRecognition)){
                        setStatus('SpeechRecognition not available', true);
                        return;
                    }

                    listening = !listening;
                    micBtn.setAttribute('aria-pressed', listening);
                    micBtn.classList.toggle('listening', listening);

                    if(listening){
                        // Try to get microphone permission first (prompts user if needed)
                        try {
                            await navigator.mediaDevices.getUserMedia({ audio: true });
                        } catch (permErr) {
                            console.warn('Microphone permission denied or unavailable', permErr);
                            setStatus('Microphone permission denied or unavailable', true);
                            // revert UI state
                            listening = false;
                            micBtn.setAttribute('aria-pressed', false);
                            micBtn.classList.remove('listening');
                            return;
                        }

                        playSound('activationSound');  // Play activation sound
                        input.placeholder = 'Listening... (type to override)';
                        input.focus();
                        try {
                            recognition.start();
                            setStatus('Listening');
                        } catch(e){
                            console.error('Start failed', e);
                            setStatus('Failed to start recognition: ' + (e.message || e), true);
                            // revert UI state
                            listening = false;
                            micBtn.setAttribute('aria-pressed', false);
                            micBtn.classList.remove('listening');
                        }
                    } else {
                        playSound('deactivationSound');  // Play deactivation sound
                        input.placeholder = 'Type or speak a command';
                        try { recognition.stop(); setStatus('Idle'); } catch(e){ console.warn('Stop failed', e); }
                    }
                });

                async function sendCommand(overrideText) {
                    const val = (typeof overrideText === 'string' ? overrideText : input.value).trim();
                    // Don't process empty commands or background noise
                    if(!val || val === "." || val === ".." || val === "..." || /^[.,\/#!$%\^&\*;:{}=\-_`~\s]+$/.test(val)) return;
                    
                    // basic debounce to prevent duplicate sends from recognition quirks
                    const now = Date.now();
                    if (now - _lastSendTs < 700) return;
                    _lastSendTs = now;
                    input.value = '';
                    setStatus('Sending command...');

                    try {
                        const resp = await fetch(`${apiBase}/api/command`, {
                            method: 'POST',
                            headers: { 'Content-Type': 'application/json' },
                            body: JSON.stringify({ command: val })
                        });
                        if(!resp.ok){
                            setStatus('Server error ' + resp.status, true);
                            const body = await resp.text();
                            console.error('Server error body:', body);
                            return;
                        }
                        const data = await resp.json();
                        const text = data.response || data.result || 'No response.';
                        console.log('Assistant:', text);
                        setStatus('Assistant responded');

                        // Open separate windows for reminders and tasks
                        if (val.toLowerCase().includes('show reminders') || val.toLowerCase().includes('read reminders') || 
                            val.toLowerCase().includes('show notes') || val.toLowerCase().includes('read notes')) {
                            const w = 400;
                            const h = 600;
                            const left = screen.availWidth - w - 20;
                            const top = 20;
                            window.open('list-view.html?type=reminders', 'AURA_reminders', 
                                `width=${w},height=${h},left=${left},top=${top},toolbar=no,location=no,status=no,menubar=no,scrollbars=yes,resizable=yes`);
                        } else if (val.toLowerCase().includes('show tasks') || val.toLowerCase().includes('list tasks')) {
                            const w = 400;
                            const h = 600;
                            const left = screen.availWidth - w - 440; // Position to the left of reminders window if open
                            const top = 20;
                            window.open('list-view.html?type=tasks', 'AURA_tasks',
                                `width=${w},height=${h},left=${left},top=${top},toolbar=no,location=no,status=no,menubar=no,scrollbars=yes,resizable=yes`);
                        }

                        // If recognition is active, stop it so TTS isn't interrupted.
                        if (recognition && listening) {
                            try {
                                shouldResumeRecognition = true;
                                recognition.stop();
                            } catch (e) { console.warn('Failed to stop recognition before TTS', e); }
                        }

                        speakText(text);
                    } catch (err) {
                        console.error('Failed to send command', err);
                        setStatus('Server unreachable', true);
                        console.warn('Could not reach server. Make sure server.py is running at http://127.0.0.1:5000');
                    }
                }

                // Robust TTS helper: waits for available voices, avoids selecting
                // an invalid voice, and provides clearer diagnostics without alerts.
                async function speakText(text){
                    if(!text) return;
                    if (!('speechSynthesis' in window)) {
                        setStatus('No TTS available', true);
                        console.log(text);
                        return;
                    }

                    // Helper: wait for voices to be populated (with timeout)
                    function waitForVoices(timeout = 2000){
                        return new Promise(resolve => {
                            let voices = window.speechSynthesis.getVoices();
                            if (voices && voices.length) return resolve(voices);

                            const onVoicesChanged = () => {
                                const v = window.speechSynthesis.getVoices();
                                if (v && v.length) {
                                    window.speechSynthesis.onvoiceschanged = null;
                                    resolve(v);
                                }
                            };

                            window.speechSynthesis.onvoiceschanged = onVoicesChanged;

                            // Fallback: resolve after timeout with whatever is available
                            setTimeout(() => {
                                window.speechSynthesis.onvoiceschanged = null;
                                resolve(window.speechSynthesis.getVoices() || []);
                            }, timeout);
                        });
                    }

                    try{
                        // ensure any ongoing speech is stopped first
                        window.speechSynthesis.cancel();

                        const voices = await waitForVoices(2500);
                        if (!voices || voices.length === 0){
                            setStatus('No TTS voices available', true);
                            console.warn('No TTS voices available; logging response instead.');
                            console.log(text);
                            return;
                        }

                        const u = new SpeechSynthesisUtterance(text);
                        u.lang = 'en-US';
                        // Set TTS to max safe volume (0.0 - 1.0)
                        try { u.volume = 1.0; } catch(e) { /* ignore if not supported */ }

                        // pick a good voice if available
                        try{
                            const preferred = voices.find(v => /Microsoft|Google|Zira|Hazel|Anna|David/i.test(v.name));
                            if (preferred) u.voice = preferred;
                            else u.voice = voices[0];
                        } catch (e){
                            console.warn('Failed to set preferred voice', e);
                        }

                        u.onerror = (e) => { console.error('TTS error', e); setStatus('TTS error', true); console.log(text); };
                        u.onstart = () => { setStatus('Speaking'); };
                        u.onend = () => { 
                            setStatus('Idle');
                            // Resume recognition if we stopped it for TTS
                            if (shouldResumeRecognition && recognition) {
                                try {
                                    recognition.start();
                                    setStatus('Listening');
                                    try{ scheduleLangFallback(); } catch(e){}
                                } catch (e) {
                                    console.warn('Failed to resume recognition after TTS', e);
                                }
                                shouldResumeRecognition = false;
                            }
                        };

                        window.speechSynthesis.speak(u);
                    } catch(e){
                        console.error('TTS failed', e);
                        setStatus('TTS failed', true);
                        console.log(text);
                    }
                }

                send.addEventListener('click', () => sendCommand());
                input.addEventListener('keydown', function(e){ if(e.key === 'Enter') sendCommand(); });

                // Compact window button — open a small popup sized like your screenshot
                const compactBtn = document.getElementById('compactBtn');
                if (compactBtn) {
                    compactBtn.addEventListener('click', () => {
                        const url = window.location.href;
                        const w = 420;
                        const h = 560;
                        const left = screen.availWidth - w - 20;
                        const top = 20;
                        window.open(url, 'AURA_compact', `toolbar=no,location=no,status=no,menubar=no,scrollbars=yes,resizable=yes,width=${w},height=${h},left=${left},top=${top}`);
                    });
                }

                // warm up voices

                // warm up voices
                if('speechSynthesis' in window){
                    window.speechSynthesis.getVoices();
                    if(window.speechSynthesis.onvoiceschanged) window.speechSynthesis.onvoiceschanged = () => window.speechSynthesis.getVoices();
                }
            })();
        </script>

</body>
</html>



